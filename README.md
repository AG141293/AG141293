Ankita Ghosh

ğŸš€ Data Science & AI Engineer | LLM Â· VLM Â· NLP Practitioner | GenAI Pipeline Builder

I specialize in transforming raw, noisy, multilingual data into high-quality, AI-ready datasets and building scalable, production-grade GenAI systems. My work spans Machine Learning, NLP, Large Language Models (LLMs), Visionâ€“Language Models (VLMs), and Generative AI, with a strong focus on real-world deployment and multilingual AI for Indian languages.

I actively build end-to-end GenAI pipelines â€” from data cleaning, validation, and augmentation to synthetic data generation, evaluation, and automation â€” ensuring robustness, correctness, and downstream usability.

ğŸŒ± Always learning, always curious.

ğŸ“ Background

Artificial Intelligence & Machine Learning

ğŸ’¡ Core Skills

Programming: Python, SQL

Data: Data Cleaning, Normalization, Validation

ML & DL: Machine Learning, Deep Learning

NLP & GenAI: LLMs, VLMs, Transformers, Prompt Engineering

Pipelines: GenAI Automation, SDG Pipelines, Evaluation Frameworks

ğŸ” Focus Areas

Large Language Models (LLMs)

Visionâ€“Language Models (VLMs)

Transformers & Prompt Engineering

Synthetic Data Generation (SDG)

Multilingual & Indic Language AI

Production-Ready GenAI Pipelines

ğŸ’¼ Experience
Machine Learning Intern â€” Makers Lab, Tech Mahindra

Project: INDUS â€” Indiaâ€™s Own Large Language Model

Worked on large-scale multilingual data preparation and augmentation for Indian language AI systems, contributing to dataset quality, robustness, and model readiness.

ğŸ§¹ Data Cleaning & Normalization (Multilingual NLP)

Designed and implemented a robust multilingual data-cleaning pipeline for Hindi and mixed-language (Hindi + English) datasets, primarily educational and concept-based (Q&A, explanations).

Key Contributions:

Text normalization (whitespace, line breaks, encoding issues)

Removal of noisy tokens and unwanted artifacts

Mixed-language handling with selective translation

Protection of mathematical symbols, formulas, units, and operators

Conversion of Hindi numerals to English digits

Logic to preserve measurements and semantic correctness

Ensured CSV encoding safety (UTF-8, UTF-16, legacy formats)

ğŸ“Œ Result: Produced clean, model-ready datasets suitable for LLM training and evaluation.

ğŸ§ª Synthetic Data Generation (10Ã— Dataset Expansion)

Built LLM-driven SDG pipelines using NVIDIA NIM (LLaMA-3.1-70B).

Highlights:

Expanded datasets 10Ã— (â‰ˆ3K â†’ 30K+ rows)

Generated high-quality Hindi MCQs with:

Difficulty levels (Easy / Medium / Hard)

Cognitive levels (Recall / Understanding / Application)

Concept-wise alignment

Designed strict JSON-only output validation

Implemented:

Retry logic & failure handling

Checkpoint-based saving

Resume-from-failure capability

Cleaned malformed LLM outputs (escaping, LaTeX, broken JSON)

ğŸ§  Core-Conceptâ€“Driven SDG

Generated synthetic questions anchored to core physics concepts, ensuring pedagogical correctness.

Conditioned generation on:

Concept name

Reference question

Educational grade constraints

ğŸ“Œ Used SDG outputs for training, evaluation, and benchmarking educational NLP models.

ğŸ—£ï¸ LLM, NLP & Speech Systems

Curated multilingual Indian dialect datasets

Built pipelines for:

Dialect classification

Annotation & validation

Created 10,000+ dialectal variants

Evaluated performance using accuracy metrics

Implemented ASR pipelines

Measured transcription accuracy using Word Error Rate (WER) (jiwer)

Integrated real-time multilingual translation

ğŸ§  GenAI, LLM & VLM Projects
ğŸ”¹ Automated Q&A Generation (LLM Pipelines)

Built an end-to-end Q&A generation system using Gemini Flash 2.5.

Pipeline:
Text â†’ Chunking â†’ Question Generation â†’ Answer Extraction â†’ Validation

Generated:

MCQs

Short-answer questions

Long descriptive answers

Interview-style questions

Implemented semantic similarity scoring and designed modular, reusable, production-ready pipelines.

ğŸ”¹ Visionâ€“Language Model (VLM) Pipelines

Worked on Vision + Text AI workflows combining OCR, document understanding, and LLMs.

Capabilities:

OCR from images & scanned PDFs

Structured extraction from visual documents

Combined visual + textual context for:

Document comprehension

Information extraction

Downstream Q&A generation

ğŸ”¹ Document Reading & Summarization Pipelines

Built intelligent document workflows:

Pipeline:
Document â†’ Chunking â†’ Summary â†’ Explanation â†’ Keywords

Section-wise summarization

Semantic search for context-aware retrieval

Automatic extraction of:

Key insights

Highlights

Glossaries

Action points

ğŸ”¹ File Conversion & AI Automation

Developed reusable utilities for:

PDF â†’ Text / JSON

Image â†’ Text (OCR)

CSV â†” Excel

Text cleaning & normalization

GenAI-based document understanding

ğŸŒ Frontend + AI Integration

Designed HTML-based UIs for:

OCR & document ingestion

Data cleaning & normalization

Q&A generation

Web scraping

File conversion

Enabled end-to-end AI workflows with user-friendly interaction.

ğŸ› ï¸ Tech Stack
Languages

Python, SQL

Frameworks & Libraries

TensorFlow, PyTorch

Pandas, NumPy, Scikit-learn

EasyOCR, jiwer

deep_translator, indic-nlp-library

GenAI / LLM / VLM

Gemini Flash 2.5

NVIDIA NIM

LLaMA-3.1

Prompt Engineering

LLM & VLM Pipelines

Synthetic Data Generation

Tools

GitHub

VS Code

Google Colab

Jupyter Notebook

ğŸ“Š Case Studies

Walmart Â· Ola Â· LoanTap Â· Delhivery Â· Netflix Â· and more

ğŸ“ Connect With Me

ğŸ”— LinkedIn: https://www.linkedin.com/in/ank1412

